12-1 Gradient Descent 기본
-Gradient Descent란?
Stationary/Critical Points : 에러함수가 제공되었을 때 기울기 0인 지점 -> 글로벌 미니멈
로컬 미니멈 , 로컬 맥시멈 , 글로벌 미니멈 , 글로벌 맥시멈

에러함수에서 글로벌 미니멈 찾는 일반적인 방법
역행렬 계산 (속도 느려짐) -> 해결 방법 : Gradient Descent

-Gradient Descent 작동 순서
이니셜 포인트 지정 -> 시작점에서 기울기 계산 -> 기울기에 방향으로 시작점 이동 -> 기울기 계산 -> 옮김 -> 반복

-Gradient Descent 장점과 단점
장점
	반복적으로 파라미터 업데이트하여 원하는 결과 얻는 알고리즘 (파라미터의 기울기 값 활용)
	미분가능한 Convex 에러함수 항상 적용 가능
	뛰어난 안정성, 정확도

단점
	컨벡스 형태 실제 사례에서 얻기 어려움


12-2 Gradient Descent 심화
-Stochastic Gradient Descent
연산량 감소를 위해 사용 -> 여러개의 데이터 샘플 중 한개만 선택한 뒤 기울기 계산

파라미터 지점 설정 -> 한 개 샘플 에러함수로 기울기 값 계산 
	-> 기준점에서 그 기준점 기준으로 한 기울기 값과 스텝 사이즈 곱의 차 계산 -> 반복
	-> 한 개 샘플은 기울기가 0에 가까워질 수 있지만 다른 샘플은 아닐 수 있기 때문에
	여러 번의 업데이트 보고 계속 0에 충분히 가까울 때 반복 멈춤

전체적인 계산량은 적음
convex할수의 경우 글로벌 미니멈에 수렴

단점
	로컬미니멈에 쉽게 빠지는 결우 있음
	데이터 크기가 너무 클 경우 너무 많은 업데이트 반복 (비효율적)

-Mini-batch Gradient Descent
여러 개의 샘플 선택
딥러닝에서 주로 사용
