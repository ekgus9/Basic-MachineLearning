{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "03_언어모델.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOxjHI7XAnbsl3Fd/awfUaS"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# 03 언어모델 Language Model\n",
        "\n",
        "### 1) 언어모델이란?\n",
        "\n",
        "  1. 언어모델\n",
        "  \n",
        "  언어라는 형상을 모델링하고자 단어 시퀀스(문장)에 확률을 할당하는 모델\n",
        "\n",
        "- 이전 단어들이 주어졌을때 다음 단어 예측\n",
        "\n",
        "- 주어진 양쪽 단어들로부터 가운데 비어있는 단어를 예측\n",
        "\n",
        "2. 단어 시퀀스의 확률 할당\n",
        "\n",
        "  a. 기계 번역\n",
        "\n",
        "  P(나는 버스를 탔다) > P(나는 버스를 태운다)\n",
        "\n",
        "  b. 오타 교정\n",
        "\n",
        "  선생님이 교실로 부리나케\n",
        "\n",
        "  P(달려갔다) > P(잘려갔다)\n",
        "\n",
        "  c. 음성인식\n",
        "\n",
        "  P(나는 메롱을 먹는다) < P(나는 메론을 먹는다)\n",
        "\n",
        "3. 주어진 이전 단어들로부터 다음 단어 예측\n",
        "\n",
        "  a. 단어 시퀀스의 확률\n",
        "\n",
        "  b. 다음 단어 등장 확률\n",
        "\n",
        "### 2) 통계적 언어 모델 Statistical Language Model, SLM\n",
        "\n",
        "1. 조건부 확률\n",
        "\n",
        "  P(B|A) = P(A,B)/P(A)\n",
        "\n",
        "2. 문장에 대한 확률 : 각 단어들이 이전 단어가 주어졌을 때 다음 단어로 등장할 확률의 곱으로 구성\n",
        "\n",
        "3. 카운트 기반 접근 : 이전 단어로부터 다음 단어의 확률 구함\n",
        "\n",
        "  P(is|the boy) = count(the boy is) / count(the boy)\n",
        "\n",
        "4. 카운트 기반 접근의 한계 : 희소 문제 (충분한 데이터를 관측하지 못하여 언어를 정확히 모델링하지 못하는 문제)\n",
        "\n",
        "### 3) N-gram 언어 모델 \n",
        "\n",
        "이전에 등장한 일부 단어만 고려\n",
        "\n",
        "1. 코퍼스에서 카운트하지 못하는 경우의 감소\n",
        "\n",
        "  P(is|An adorable little boy) ~> P(is|boy)\n",
        "\n",
        "2. N-gram의 한계 \n",
        "\n",
        "- 희소문제\n",
        "- n을 선택하는 것은 trade-off 문제 (은 최대 5를 넘게 잡아서는 안된다)\n",
        "- 전체 문장을 고려한 언어 모델보다는 정확도 떨어짐\n",
        "\n",
        "3. 적용 분야에 맞는 코퍼스 수집\n",
        "\n",
        "### 4) 한국어에서의 언어 모델\n",
        "\n",
        "1. 한국어에는 어순이 중요하지 않다.\n",
        "2. 한국어는 교착어이다.\n",
        "  ex. 그녀가, 그녀를, 그녀의, 그녀와, ...\n",
        "3. 한국어는 띄어쓰기가 제대로 지켜지지 않는다.\n",
        "\n",
        "### 5) 펄플렉서티 Perplexity, PPL\n",
        "\n",
        "모델 내에서 자신의 성능을 수치화\n",
        "\n",
        "1. 언어 모델의 평가 방법 PPL\n",
        "\n",
        "  문장의 길이로 정규화된 문장 확률의 역수 -> **수치가 낮을수록** 모델 성능이 좋음을 의미\n",
        "\n",
        "2. 분기 계수 Branching factor\n",
        "\n",
        "  선택할 수 있는 가능한 경우의 수 PPL : PPL이 10이라면 해당 언어 모델이 편균 10개의 단어를 가지고 어떤 것이 정답인지 고민한 것\n",
        "\n",
        "  But, PPL이 낮다는 것은 테스트 데이터 상 높은 정확도를 의미하는 것이지, 사람이 느끼기에 좋은 모델이라는 의미는 아니다."
      ],
      "metadata": {
        "id": "XHSPG_mz-w2-"
      }
    }
  ]
}